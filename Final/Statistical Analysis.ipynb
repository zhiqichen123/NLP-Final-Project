{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('News_Category_Dataset_v2.json', 'r') as f:\n",
    "    news = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_short_description = []\n",
    "for new in news:\n",
    "    news_short_description.append(new['short_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def is_content_word(word):\n",
    "    return word.lower() not in stopwords and word.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of descriptions: 200853\n",
      "Average length of descriptions: 23\n"
     ]
    }
   ],
   "source": [
    "news_description_words = []\n",
    "news_description_allwords = []\n",
    "for des in news_short_description:\n",
    "    for w in nltk.word_tokenize(des):\n",
    "        news_description_allwords.append(w)\n",
    "        if is_content_word(w):\n",
    "            news_description_words.append(w) \n",
    "\n",
    "num_of_description = len(news_short_description)\n",
    "print('The number of descriptions: {}'.format(num_of_description))\n",
    "avg_wordlen_description = round(len(news_description_allwords) / len(news_short_description))\n",
    "print('Average length of descriptions: {}'.format(avg_wordlen_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences: 280300\n",
      "Average number of sentences of descriptions: 1.396\n"
     ]
    }
   ],
   "source": [
    "num_of_sen = 0\n",
    "for des in news_short_description:\n",
    "    num_of_sen =  num_of_sen + len(nltk.sent_tokenize(des))\n",
    "print('The number of sentences: {}'.format(num_of_sen))\n",
    "avg_senlen_description = round(num_of_sen / len(news_short_description), 3)\n",
    "print('Average number of sentences of descriptions: {}'.format(avg_senlen_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 most common words:\n",
      "[('one', 11060), ('time', 8840), ('people', 8603), ('like', 8160), ('new', 6886), ('us', 6869), ('said', 6414), ('would', 6055), ('get', 5869), ('life', 5846), ('make', 5399), ('know', 5320), ('Trump', 5159), ('many', 5081), ('years', 4909), ('first', 4876), ('way', 4839), ('world', 4814), ('could', 4771), ('may', 4574), ('year', 4466), ('day', 4366), ('want', 4252), ('even', 4160), ('need', 4025)]\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(news_description_words)\n",
    "print('25 most common words:')\n",
    "print(fdist.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 most common words:\n",
      "[(('New', 'York'), 1689), (('Donald', 'Trump'), 1650), (('United', 'States'), 894), (('years', 'ago'), 739), (('HuffPost', 'Style'), 699), (('White', 'House'), 698), (('first', 'time'), 605), (('Hillary', 'Clinton'), 573), (('health', 'care'), 527), (('last', 'week'), 518), (('last', 'year'), 434), (('York', 'City'), 429), (('social', 'media'), 421), (('every', 'day'), 416), (('climate', 'change'), 411), (('Supreme', 'Court'), 409), (('feel', 'like'), 403), (('many', 'people'), 391), (('one', 'thing'), 372), (('President', 'Obama'), 368), (('Los', 'Angeles'), 349), (('new', 'study'), 326), (('make', 'sure'), 298), (('New', 'Year'), 289), (('high', 'school'), 285)]\n"
     ]
    }
   ],
   "source": [
    "content_bigrams = [bigram for bigram in list(nltk.bigrams(news_description_allwords))\n",
    "                    if is_content_word(bigram[0]) and is_content_word(bigram[1])]\n",
    "bigrams_fdist = nltk.FreqDist([bigram for bigram in content_bigrams])\n",
    "print('25 most common words:')\n",
    "print(bigrams_fdist.most_common(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 most common trigrams:\n",
      "[(('New', 'York', 'City'), 429), (('New', 'York', 'Times'), 254), (('HuffPost', 'Rise', 'Morning'), 193), (('Rise', 'Morning', 'Newsbrief'), 193), (('President', 'Donald', 'Trump'), 164), (('President', 'Barack', 'Obama'), 132), (('Affordable', 'Care', 'Act'), 122), (('political', 'news', 'every'), 108), (('news', 'every', 'evening'), 107), (('home', 'story', 'idea'), 105), (('Saturday', 'Night', 'Live'), 96), (('New', 'York', 'Fashion'), 96), (('PR', 'pitches', 'sent'), 95), (('York', 'Fashion', 'Week'), 90), (('need', 'help', 'maintaining'), 79), (('personal', 'spiritual', 'practice'), 79), (('Kids', 'may', 'say'), 69), (('HuffPost', 'Style', 'beauty'), 59), (('Style', 'beauty', 'content'), 58), (('Fox', 'News', 'host'), 55), (('Mother', 'Nature', 'Network'), 53), (('popular', 'YouTube', 'videos'), 50), (('World', 'War', 'II'), 49), (('Twitter', 'never', 'fail'), 49), (('new', 'study', 'suggests'), 49)]\n"
     ]
    }
   ],
   "source": [
    "content_trigrams = [trigram for trigram in list(nltk.trigrams(news_description_allwords))\n",
    "                    if is_content_word(trigram[0]) and is_content_word(trigram[1]) and is_content_word(trigram[2])]\n",
    "trigrams_fdist = nltk.FreqDist([trigram for trigram in content_trigrams])\n",
    "print('25 most common trigrams:')\n",
    "print(trigrams_fdist.most_common(25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
